First
of all, should lower (LB) and higher bands (HB) modelled
by  separate  networks  or  using  common  representation  and
layers.  

Secondly, how much does the reconstruction of the
lower band improve speech quality in absence of noise?

How
much does the expansion improve the quality as opposed to
simple denoising?


-----------------------------------

Efficiency of AI

Alternate formulations... 
-> people done it a lot for sure

-> hierarchy of features
-> linearity (or quasi-linearity) of solution (non-exponential)



What is going on in filters?




Learning and searching scales



IDEA: Neural lib for fitting for sound
-> different complexity





Use DropIn To log Events and launch periodic task of mailing results to me


Hackathon:
https://www.facebook.com/events/456368795175172/?notif_t=event_calendar_create&notif_id=1556167525934481



Common vision features

-=-=-=-

Challenges for AI:
-> Safety, fairness, explainability

Teaching: sparse information directing learning
Representation matters
Humans in the loop


Queries AI systems - next big thing, XXI century

Reduce ammount of data annotation


0.3% on single instance of each digit of MNIST -> the problem

AI systems that can tell "I don't know"


Arguing machines
- they improve classification
- high role of uncertainty signal arising from disagreement

